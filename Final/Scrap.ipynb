{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create PySpark context\n",
    "from pyspark import  SparkContext, SQLContext, Row\n",
    "sc = SparkContext('local', 'pyspark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Book Data into Spark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([u'Classical', u'Mythology', u'Mark', u'P.', u'O.', u'Morford'], 0),\n",
       " ([u'Clara', u'Callan', u'Richard', u'Bruce', u'Wright'], 1)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_filename = \"BX-Books.csv\"\n",
    "book_filename = \"books-mini.csv\"\n",
    "\n",
    "book_raw_data = sc.textFile(book_filename)\n",
    "book_raw_data_header = [ word.replace(\"\\\"\", \"\") for word in book_raw_data.take(1)[0].split(';')[1:3] ] # Used to skip the header\n",
    "book_raw_data =  book_raw_data.map(lambda line: [ word.replace(\"\\\"\", \"\") for word in line.split(\";\")[1:3]]) \\\n",
    "                            .filter(lambda line: line != book_raw_data_header) \\\n",
    "                            .map(lambda line: \"%s %s\" % (line[0], line[1])) \\\n",
    "                            .map(lambda line: line.split(\" \")).zipWithIndex()\n",
    "book_raw_data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Table for lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(idx=400, title=[u\"Alice's\", u'Adventures', u'in', u'Wonderland', u'and', u'Through', u'the', u'Looking', u'Glass', u'Lewis', u'Carroll'])]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "book_table = book_raw_data.map(lambda p: Row(idx=p[1], title=p[0]))\n",
    "schema_books = sqlContext.createDataFrame(book_table)\n",
    "schema_books.registerTempTable(\"books\")\n",
    "\n",
    "# example\n",
    "book = sqlContext.sql(\"SELECT * FROM books WHERE idx = 400 LIMIT 1\")\n",
    "book.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'Classical', u'Mythology', u'Mark', u'P.', u'O.', u'Morford']]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = sqlContext.sql(\"SELECT title FROM books\").map(lambda row: row[0])\n",
    "titles.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TFIDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF\n",
    "hashingTF = HashingTF()\n",
    "tf = hashingTF.transform(titles)\n",
    "from pyspark.mllib.feature import IDF\n",
    "tf.cache()\n",
    "idf = IDF().fit(tf)\n",
    "tfidf = idf.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LSH Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark_lsh import lsh\n",
    "# p : integer, larger than the largest value in data.\n",
    "# m : integer, number of bins for hashing.\n",
    "# n : integer, number of rows to split the signatures into.\n",
    "# b : integer, number of bands. Each band will have (n / b) element\n",
    "# c : integer, minimum allowable cluster size.\n",
    "lsh_model = lsh.run(tfidf, p = 1000, m = 100, n = 50, b = 10, c = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[32, 45.799693773357461],\n",
       " [4, 391.70507534087301],\n",
       " [6, 20.807461685823753],\n",
       " [8, 70.809365250332746],\n",
       " [10, 362.85477638830855],\n",
       " [16, 27.90909090909091],\n",
       " [18, 21.430256676173194],\n",
       " [20, 52.836774274343924],\n",
       " [26, 137.35868748984092],\n",
       " [30, 134.54889207369865],\n",
       " [3, 23.558127355960174],\n",
       " [35, 25.109014560318908],\n",
       " [13, 30.076869617310788],\n",
       " [17, 112.53723713897934],\n",
       " [19, 27.675226714128318],\n",
       " [23, 71.729652649726546],\n",
       " [25, 20.366054340396449],\n",
       " [27, 116.63559025570666],\n",
       " [29, 436.83751625564366],\n",
       " [39, 103.38084737407289]]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets_to_check = lsh_model.scores.filter(lambda bucket_score: bucket_score[1] > 20).collect()\n",
    "buckets_to_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Titles within All Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_merge_list = {}\n",
    "\n",
    "def parent(rep, v):\n",
    "    if rep[v] == v:\n",
    "        return v\n",
    "    rep[v] = parent(rep, rep[v])\n",
    "    return rep[v]\n",
    "\n",
    "def merge(rep, L):\n",
    "    for edge in L:\n",
    "        u, v = edge\n",
    "        if u not in rep:\n",
    "            rep[u] = u\n",
    "        if v not in rep:\n",
    "            rep[v] = v\n",
    "        rep[parent(rep, v)] = parent(rep, u)\n",
    "    return rep\n",
    "\n",
    "def jaccard(a, b):\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.04501390457\n",
      "4.74173903465\n",
      "0.988847017288\n",
      "1.82256293297\n",
      "3.73498296738\n",
      "1.12818312645\n",
      "1.11541390419\n",
      "1.54771590233\n",
      "3.44589614868\n",
      "3.1401848793\n",
      "1.44131398201\n",
      "1.11329102516\n",
      "1.72583198547\n",
      "2.37709593773\n",
      "1.10212802887\n",
      "1.84017014503\n",
      "0.981561183929\n",
      "2.14570498466\n",
      "4.44558501244\n",
      "2.47338795662\n",
      "{308: 308,\n",
      " 405: 308,\n",
      " 500: 563,\n",
      " 501: 553,\n",
      " 502: 502,\n",
      " 503: 567,\n",
      " 504: 504,\n",
      " 505: 502,\n",
      " 506: 568,\n",
      " 507: 567,\n",
      " 508: 504,\n",
      " 509: 553,\n",
      " 510: 502,\n",
      " 530: 530,\n",
      " 540: 540,\n",
      " 553: 553,\n",
      " 554: 530,\n",
      " 563: 563,\n",
      " 567: 567,\n",
      " 568: 568,\n",
      " 571: 568,\n",
      " 576: 576,\n",
      " 591: 576,\n",
      " 593: 540,\n",
      " 599: 553,\n",
      " 604: 568}\n"
     ]
    }
   ],
   "source": [
    "for (bucket_idx, score) in buckets_to_check:\n",
    "    start = time.time()\n",
    "    \n",
    "    bv = lsh_model.buckets_vectors.filter(lambda bv: bv[0] == bucket_idx)\n",
    "    # print bv.collect()\n",
    "\n",
    "    books_in_bucket = []\n",
    "    for x in bv.collect():\n",
    "        books_in_bucket.append(sqlContext.sql(\"select * from books where idx = %s\" % x[1]) \\\n",
    "                                        .map(lambda row: (row[0], row[1])).collect()[0])\n",
    "    # books_in_bucket\n",
    "    \n",
    "    to_merge = []\n",
    "    for idx1, book1 in enumerate(books_in_bucket):\n",
    "        (gidx1, title1) = book1\n",
    "        for idx2 in range(idx1+1, len(books_in_bucket)):\n",
    "            book2 = books_in_bucket[idx2]\n",
    "            (gidx2, title2) = book2\n",
    "\n",
    "            x = set(title1)\n",
    "            y = set(title2)\n",
    "\n",
    "            if jaccard(x,y) > 0.85:\n",
    "                to_merge.append((gidx1, gidx2))\n",
    "    \n",
    "    #pprint(to_merge)\n",
    "    \n",
    "    merge(global_merge_list, to_merge)\n",
    "    \n",
    "    print(time.time() - start)\n",
    "\n",
    "pprint(global_merge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(idx=530, title=[u'Harry', u'Potter', u'and', u'the', u'Chamber', u'of', u'Secrets', u'J.', u'K.', u'Rowling'])]\n",
      "[Row(idx=540, title=[u'J.', u'K.', u'Rowling:', u'The', u'Wizard', u'Behind', u'Harry', u'Potter', u'Marc', u'Shapiro'])]\n",
      "[Row(idx=553, title=[u'Harry', u'Potter', u'and', u'the', u\"Sorcerer's\", u'Stone', u'(Book', u'1)', u'J.', u'K.', u'Rowling'])]\n",
      "[Row(idx=563, title=[u'Harry', u'Potter', u'and', u'the', u\"Sorcerer's\", u'Stone', u'(Harry', u'Potter', u'(Paperback))', u'J.', u'K.', u'Rowling'])]\n",
      "[Row(idx=308, title=[u'The', u'Perfect', u'Storm', u':', u'A', u'True', u'Story', u'of', u'Men', u'Against', u'the', u'Sea', u'Sebastian', u'Junger'])]\n",
      "[Row(idx=567, title=[u'Harry', u'Potter', u'and', u'the', u'Prisoner', u'of', u'Azkaban', u'(Book', u'3)', u'J.', u'K.', u'Rowling'])]\n",
      "[Row(idx=568, title=[u'Harry', u'Potter', u'and', u'the', u'Order', u'of', u'the', u'Phoenix', u'(Book', u'5)', u'J.', u'K.', u'Rowling'])]\n",
      "[Row(idx=576, title=[u'The', u'Science', u'of', u'Harry', u'Potter:', u'How', u'Magic', u'Really', u'Works', u'Roger', u'Highfield'])]\n",
      "[Row(idx=502, title=[u'Harry', u'Potter', u'and', u'the', u'Chamber', u'of', u'Secrets', u'(Book', u'2)', u'J.', u'K.', u'Rowling'])]\n",
      "[Row(idx=504, title=[u'Harry', u'Potter', u'and', u'the', u'Goblet', u'of', u'Fire', u'(Book', u'4)', u'J.', u'K.', u'Rowling'])]\n"
     ]
    }
   ],
   "source": [
    "for merge1, merge2 in global_merge_list.iteritems():\n",
    "    if merge1 == merge2:\n",
    "        book = sqlContext.sql(\"SELECT * FROM books WHERE idx = %s LIMIT 1\" % merge1)\n",
    "        print book.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(idx=521, title=[u'Harry', u'Potter', u'y', u'el', u'c\\xe1liz', u'de', u'fuego', u'J.', u'K.', u'Rowling'])]\n"
     ]
    }
   ],
   "source": [
    "book = sqlContext.sql(\"SELECT * FROM books WHERE idx = %s LIMIT 1\" % 521)\n",
    "print book.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "\n",
    "* Try KMeans from mllib, to avoid python_lsh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "----\n",
    "\n",
    "## Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[103] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh_model.buckets_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsh_model.buckets.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(1048576, {1026665: 1.0, 1034736: 1.0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tf = HashingTF()\n",
    "test_tf.transform([\"james\", \"q\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "maxvals = tfidf.map(max)\n",
    "\n",
    "maxvals.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
