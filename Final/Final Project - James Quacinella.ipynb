{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS622 Final Project: Book Recommendations\n",
    "### An Extension of Week12's Recommendation Project\n",
    "\n",
    "## Background \n",
    "\n",
    "For this final project, I will extend the work done in Week 12 where I built a recommender system for ratings data for books. As a recap on what that project was about, I used data on book ratings from [this data set](http://www2.informatik.uni-freiburg.de/~cziegler/BX/). This data set has 1 millon+ rows of user ratings (from 1 - 10) of books identified by ISBN number. \n",
    "\n",
    "I used this data to generate a recommendation system using PySpark. The model developed used matrix factorization to allow us to take in a set of ratings for a new user, and predict their ratings for any other book in our data. The conclusion from Week12, however, was that the model generated was not so great with respect to how accurate the matrix factorization reproduced the original data. \n",
    "\n",
    "One idea to improve its performance was to go through a round of de-duplication: there are books that have different ISBN numbers but are essentially the same book l(two different volumes of same book, for example). De-duplication will be done by some kind of locality sensitive hashing to determine titles that are similar enough to consider merge-worthy. I found a [Spark implementation of LSH in python](https://github.com/magsol/pyspark-lsh/) and will use it to efficently find similar books by titles.\n",
    "\n",
    "My hypothesis is that de-duplicating the data (books in this case) and merging ratings from both books into one would help the accuracy of the model. \n",
    "\n",
    "The model will be compared to Week12's results to see if the accuracy (based on a train-validation-test set split) has improved. The model will also be compared to see how much better it performs in execution time.\n",
    "\n",
    "## Data Defintion\n",
    "\n",
    "The Book-Crossing dataset comprises 3 tables.\n",
    "\n",
    "* **BX-Users:** Contains the users. Note that user IDs (`User-ID`) have been anonymized and map to integers. \n",
    "    * For our purposes, we do not nee this file\n",
    "\n",
    "\n",
    "* **BX-Books** - Books are identified by their respective ISBN. Invalid ISBNs have already been removed from the dataset. Moreover, some content-based information is given (`Book-Title`, `Book-Author`, `Year-Of-Publication`, `Publisher`), obtained from Amazon Web Services. \n",
    "    * We load this manually to convert ISBN numbers to an internal index number to be used in the model\n",
    "\n",
    "\n",
    "* **BX-Book-Ratings** - Contains the book rating information. Ratings (`Book-Rating`) are either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0.\n",
    "    * This is the main file we load, which consists of more than one mullion rows. However, we filter out books that do not appear in the above BX-Books file (why this happens I am not sure). \n",
    "\n",
    "Git does not allow large files, so they are not in the git repo. The file 'BX-CSV-Dump.zip' can be unzipped and the data files will be loaded.\n",
    "\n",
    "## Objective\n",
    "\n",
    "My hypothesis is that de-duplicating the data (books in this case) and merging ratings from merged books will help the accuracy of the model as measured by the RMSE of the model on a validation data set.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Overview\n",
    "\n",
    "* First, we will review the original model and how it was built, and associated RMSE values\n",
    "    * Create a small snippet of the data, and search for the best rank metaparameter based on validation set RMSE\n",
    "    * Use this meta parameter for the medium sized data (500000 rows) and the full data (1000000+ rows) and find the test set RMSE\n",
    "* Next we will perform de-duplication of books, merging the reviews together\n",
    "* We will then create a second model with the de-duplication in place\n",
    "* Finally, we will compare performances of these models\n",
    "\n",
    "**NOTE:** Going forward, the code that follows was executed on an EC2 server, so I am copying and pasting final code and results. [Another notebook](http://nbviewer.ipython.org/github/jquacinella/IS622_Repository/blob/master/Final/IS622%20Final%20-%20Generating%20Merge%20with%20LSH.ipynb) has the work in how the merge dictionary is generated, with output from the server\n",
    "\n",
    "### Recapping Week 12 - Load Data into Spark\n",
    "\n",
    "The code below loads the Book information into a Spark RDD object (this is a listing of tuples of (ISBN, title)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure the necessary Spark environment\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import itable\n",
    "import pandas as pd\n",
    "\n",
    "# We are using ALS to factor our user-to-book rating matrix\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "# Create PySpark context\n",
    "from pyspark import  SparkContext, SQLContext, Row\n",
    "sc = SparkContext('local[*]', '--executor-memory=8g pyspark')\n",
    "# sc.defaultParallelism ## 16\n",
    "\n",
    "# Read in file into RDD\n",
    "book_filename = \"/spark/BX-Books.csv\"\n",
    "book_raw_data = sc.textFile(book_filename)\n",
    "\n",
    "# Used to skip the header\n",
    "book_raw_data_header = [ word.replace(\"\\\"\", \"\") \n",
    "                        for word in book_raw_data.take(1)[0].split(';')[1:3] ] \n",
    "\n",
    "# Filter out quotes after splitting line by ; delim and keeping only what we need\n",
    "book_raw_data =  book_raw_data.map(lambda line: [ word.replace(\"\\\"\", \"\") \n",
    "                                                 for word in line.split(\";\")[1:3]]) \\\n",
    "                            .filter(lambda line: line != book_raw_data_header) \\\n",
    "                            .map(lambda line: \"%s %s\" % (line[0], line[1]))\n",
    "\n",
    "# Confirm data loaded\n",
    "# book_raw_data.take(5)\n",
    "\n",
    "# Read in book data into global dict which maps isbn to title\n",
    "isbn_to_idx = { }\n",
    "isbn_idx = 0\n",
    "book_data = open(\"BX-Books.csv\", \"r\")\n",
    "for line in book_data.readlines():\n",
    "    # Split the line and filter out quotes\n",
    "    (isbn, title) = line.split(';')[0:2]\n",
    "    isbn = isbn.replace(\"\\\"\", \"\")\n",
    "    title = title.replace(\"\\\"\", \"\")\n",
    "    \n",
    "    # Store in mapping\n",
    "    isbn_to_idx[isbn] = isbn_idx\n",
    "    isbn_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the Ratings information into a Spark RDD object. Ratings file is just a list of tuples of the form (user_id, isbn, rating of isbn). This is a useful format for ALS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in chosen data set (min = 5000 lines, half=50000)\n",
    "ratings_filename = \"BX-Book-Ratings.csv\"\n",
    "# ratings_filename = \"BX-Book-Ratings.half.csv\"\n",
    "# ratings_filename = 'BX-Book-Ratings.min.csv'\n",
    "ratings_raw_data = sc.textFile(ratings_filename)\n",
    "ratings_raw_data_header = ratings_raw_data.take(1)[0] # Used to skip the header\n",
    "\n",
    "\n",
    "# Given a row from the file, filter out quotes and create dict of isbn -> index\n",
    "def convert_row(tokens):\n",
    "    (user_id, isbn, rating) = (tokens[0].replace(\"\\\"\", \"\"), \\\n",
    "                               tokens[1].replace(\"\\\"\", \"\"), \\\n",
    "                               tokens[2].replace(\"\\\"\", \"\"))\n",
    "    \n",
    "    # Filter out implicit ratings\n",
    "    if rating == 0:\n",
    "        return (None, None, None)\n",
    "    \n",
    "    # Convert isbn to index and ...\n",
    "    global isbn_to_idx\n",
    "    if isbn in isbn_to_idx:\n",
    "        isbn_idx = isbn_to_idx[isbn]\n",
    "    else:\n",
    "        return (None, None, None)\n",
    "    \n",
    "    # ... use it in ratings row for data frame\n",
    "    return (user_id, isbn_idx, rating)\n",
    "\n",
    "# Read in raw rating data and convert it to proper format\n",
    "ratings_data = ratings_raw_data \\\n",
    "                    .filter(lambda line: line != ratings_raw_data_header) \\\n",
    "                    .map(lambda line: line.split(\";\")) \\\n",
    "                    .map(lambda tokens: convert_row(tokens)) \\\n",
    "                    .filter(lambda tokens: tokens[0] is not None).cache()\n",
    "\n",
    "# Print number of ratings loaded\n",
    "print \"Loaded %d ratings\" % ratings_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the ratings data is loaded, lets create a training, validation and testing split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training, validation and test split\n",
    "training_RDD, validation_RDD, test_RDD = ratings_data.randomSplit([70, 15, 15], seed=0L)\n",
    "\n",
    "# Trim off the rating to get user-book pairs for the validation set\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "# Trim off the rating to get user-book pairs for the test set\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train an ALS models of various rank and pick the best one based on minimizing validation RMSE error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(training_RDD, validation_for_predict_RDD, validation_RDD):\n",
    "    # Model parameters\n",
    "    seed = 5L\n",
    "    iterations = 10\n",
    "    # iterations = 20\n",
    "    regularization_parameter = 0.1\n",
    "\n",
    "    ranks = range(20, 50, 2)\n",
    "    # ranks = [30] # Found by running on min data\n",
    "#     ranks = [36]   #  Found by running on min data, but with filtering on implicit feeback\n",
    "\n",
    "    errors = [ ]\n",
    "\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_iteration = -1\n",
    "    best_model = None\n",
    "\n",
    "    # Look for best ALS model iterating over diff rank values\n",
    "    for rank in ranks:\n",
    "        # Create ALS model\n",
    "        model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations, \\\n",
    "                          lambda_=regularization_parameter)\n",
    "\n",
    "        # Come up with predictions for the validation set\n",
    "        predictions = model.predictAll(validation_for_predict_RDD)\\\n",
    "                            .map(lambda r: ((r[0], r[1]), r[2]))\n",
    "\n",
    "        # TODO\n",
    "        rates_and_preds = validation_RDD\\\n",
    "                            .map(lambda r: ((int(r[0]), int(r[1])), float(r[2])))\\\n",
    "                            .join(predictions)\n",
    "\n",
    "        # Record and update the error\n",
    "        error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "        errors.append(error)\n",
    "\n",
    "        # What is the current RMSE\n",
    "        print 'For rank %s the RMSE is %s' % (rank, error)\n",
    "\n",
    "        # Error update\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_rank = rank\n",
    "            best_model = model\n",
    "\n",
    "    # Final output\n",
    "    print 'The best model was trained with rank %s' % best_rank\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Train model\n",
    "best_model_pre_merge = train_model(training_RDD, validation_for_predict_RDD, validation_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "----\n",
    "\n",
    "----\n",
    "\n",
    "----\n",
    "\n",
    "### Finding Titles to Merge\n",
    "\n",
    "To find the titles to merge together, we need to compare each title to all other titles in the corpus to find which ones are similar (using an appropriate distance metric, like jaccard distance). However, with 200000+ books, this is not feasible. Locality sensitive hashing can help by binning titiles together that are more likely to be similar, to reduce the number of comparisons one has to do. As alluded to above, there is a [Spark implementation of LSH in python](https://github.com/magsol/pyspark-lsh/) which I will use to find book titles that are similar enough to merge. \n",
    "\n",
    "However, even with LSH, I found it necessary to use an Amazon EC2 server to get things done. Using spot instances, I setup a 16 core / 30Gb machine (or whatever was available that had som decent resources) and installed / setup ipython to use Spark. I made sure all data was stored on an EBS volume to make sure that no data was lost if the spot instance died.\n",
    "\n",
    "After that, I experimented with LSH parameters on a small subset of the data. Even with these resources, I could not process the whole set, but in two sets of 50,000 books at a time. Note: doing it this way does not mean LSH was applied to 100,000 titles, as it was applied to two subsets (i.e. LSH is not applied across the groups, so no matching is done there).\n",
    "\n",
    "The code in the other [ipython notebook](http://nbviewer.ipython.org/github/jquacinella/IS622_Repository/blob/master/Final/IS622%20Final%20-%20Generating%20Merge%20with%20LSH.ipynb) is responsible for loading the book titles into a Spark RDD object, creating an appropriate TFIDF representation of all titles, and passing the TFIDF results to the PythonLSH module. This part of the process can take 40m to a few hours depending on the size of the dataset. I found the LSH implementation took up a lot of memory. I tried tweaking the params as best as I could, but I was still limited. See the \"Next Steps\" section below for more details.\n",
    "\n",
    "### Merge Titles\n",
    "\n",
    "Using the results from LSH, I tend compare titles that are in each bucket, and construct a merge dictionary that maps an ISBN 'index' to an index of a title to merge it with. I serialize this dictionary to save my work as I go, and then load this in another notebook to perform the actual merging when loading ratings. As the rating data is loaded in, the ISBN is converted to an index and the dictionary is consulted to see if this so should be merged (i.e., another index is used). Therefore, all ratings for many titles for the same book will refer to one index.\n",
    "\n",
    "Here we will use the merge dictionary generated from the first 50,000 books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"/spark/merge_dict_v1_p100m100n50b10c5_xlarge\", \"rb\")\n",
    "merge_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# Use spark accumulators to see how many times we merge\n",
    "count = sc.accumulator(0)\n",
    "missed_count = sc.accumulator(0)\n",
    "\n",
    "def merge_ratings(tokens):\n",
    "    global count\n",
    "    global missed_count\n",
    "    # (user_id, isbn_idx, rating)\n",
    "    orig_isbn_idx = tokens[1]\n",
    "    \n",
    "    if orig_isbn_idx in merge_dict:\n",
    "        count += 1\n",
    "        return (tokens[0], merge_dict[orig_isbn_idx], tokens[2])\n",
    "    else:\n",
    "        missed_count += 1\n",
    "        return tokens\n",
    "\n",
    "# Read in raw rating data and convert it to proper format\n",
    "new_ratings_data = ratings_raw_data \\\n",
    "                    .filter(lambda line: line != ratings_raw_data_header) \\\n",
    "                    .map(lambda line: line.split(\";\")) \\\n",
    "                    .map(lambda tokens: convert_row(tokens)) \\\n",
    "                    .filter(lambda tokens: tokens[0] is not None) \\\n",
    "                    .map(merge_ratings).cache()\n",
    "\n",
    "# print \"Loaded %d ratings\" % new_ratings_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the count values, only about 8% of reviews were merged. Not a huge matching but again, only evaluated a portion of the books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data From New Post-Merged Ratings Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training, validation and test split\n",
    "training_RDD, validation_RDD, test_RDD = new_ratings_data.randomSplit([70, 15, 15], seed=0L)\n",
    "\n",
    "# Trim off the rating to get user-book pairs for the validation set\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "# Trim off the rating to get user-book pairs for the test set\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_post_merge = train_model(training_RDD, validation_for_predict_RDD, validation_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Discussions\n",
    "\n",
    "Lets compare the pre and post-merge RMSE errors for models of different rank sizes using only the first 50,000 titles and the first 100,000 titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><table style=\"color: black;border: 1px solid black;\"><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;font-weight: bold;background-color: lightgray;\">Rank</td><td style=\"color: black;font-weight: bold;background-color: lightgray;\">Pre-Merge RMSE</td><td style=\"color: black;font-weight: bold;background-color: lightgray;\">Post-Merge RMSE (50k)</td><td style=\"color: black;font-weight: bold;background-color: lightgray;\">RMSE Delta (50k)</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">20.0</td><td style=\"color: black;border: 1px solid black;\">4.26313112355</td><td style=\"color: black;border: 1px solid black;\">4.25828212238</td><td style=\"color: black;border: 1px solid black;\">0.00484900117</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">22.0</td><td style=\"color: black;border: 1px solid black;\">4.23259538535</td><td style=\"color: black;border: 1px solid black;\">4.23275657208</td><td style=\"color: black;border: 1px solid black;\">0.00016118673</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">24.0</td><td style=\"color: black;border: 1px solid black;\">4.21148751659</td><td style=\"color: black;border: 1px solid black;\">4.20943547919</td><td style=\"color: black;border: 1px solid black;\">0.0020520374</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">26.0</td><td style=\"color: black;border: 1px solid black;\">4.18826859766</td><td style=\"color: black;border: 1px solid black;\">4.18930658745</td><td style=\"color: black;border: 1px solid black;\">0.00103798979</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">28.0</td><td style=\"color: black;border: 1px solid black;\">4.16448657922</td><td style=\"color: black;border: 1px solid black;\">4.16958226847</td><td style=\"color: black;border: 1px solid black;\">0.00509568925</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">30.0</td><td style=\"color: black;border: 1px solid black;\">4.15846533055</td><td style=\"color: black;border: 1px solid black;\">4.15713268602</td><td style=\"color: black;border: 1px solid black;\">0.00133264453</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">32.0</td><td style=\"color: black;border: 1px solid black;\">4.1436364273</td><td style=\"color: black;border: 1px solid black;\">4.1416517817</td><td style=\"color: black;border: 1px solid black;\">0.0019846456</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">34.0</td><td style=\"color: black;border: 1px solid black;\">4.12220323035</td><td style=\"color: black;border: 1px solid black;\">4.12264843619</td><td style=\"color: black;border: 1px solid black;\">0.00044520584</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">36.0</td><td style=\"color: black;border: 1px solid black;\">4.11941536673</td><td style=\"color: black;border: 1px solid black;\">4.11715783255</td><td style=\"color: black;border: 1px solid black;\">0.00225753418</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">38.0</td><td style=\"color: black;border: 1px solid black;\">4.10410432488</td><td style=\"color: black;border: 1px solid black;\">4.10227015671</td><td style=\"color: black;border: 1px solid black;\">0.00183416817</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">40.0</td><td style=\"color: black;border: 1px solid black;\">4.09841351419</td><td style=\"color: black;border: 1px solid black;\">4.09726798097</td><td style=\"color: black;border: 1px solid black;\">0.00114553322</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">42.0</td><td style=\"color: black;border: 1px solid black;\">4.09207336934</td><td style=\"color: black;border: 1px solid black;\">4.08903422579</td><td style=\"color: black;border: 1px solid black;\">0.00303914355</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">44.0</td><td style=\"color: black;border: 1px solid black;\">4.08177248426</td><td style=\"color: black;border: 1px solid black;\">4.07665148098</td><td style=\"color: black;border: 1px solid black;\">0.00512100328</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"font-weight: bold;\">46.0</td><td style=\"font-weight: bold;\">4.07279330036</td><td style=\"font-weight: bold;\">4.06946764295</td><td style=\"font-weight: bold;\">0.00332565741</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">48.0</td><td style=\"color: black;border: 1px solid black;\">4.07400818709</td><td style=\"color: black;border: 1px solid black;\">4.07036979413</td><td style=\"color: black;border: 1px solid black;\">0.00363839296</td></tr></table></center>"
      ],
      "text/plain": [
       "<itable.itable.PrettyTable at 0x7f15cbb4d750>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [(20, 4.26313112355, 4.25828212238),\n",
    "         (22, 4.23259538535, 4.23275657208),\n",
    "         (24, 4.21148751659, 4.20943547919),\n",
    "         (26, 4.18826859766, 4.18930658745),\n",
    "         (28, 4.16448657922, 4.16958226847),\n",
    "         (30, 4.15846533055, 4.15713268602),\n",
    "         (32, 4.1436364273, 4.1416517817),\n",
    "         (34, 4.12220323035, 4.12264843619),\n",
    "         (36, 4.11941536673, 4.11715783255),\n",
    "         (38, 4.10410432488, 4.10227015671),\n",
    "         (40, 4.09841351419, 4.09726798097),\n",
    "         (42, 4.09207336934, 4.08903422579),\n",
    "         (44, 4.08177248426, 4.07665148098),\n",
    "         (46, 4.07279330036, 4.06946764295),\n",
    "         (48, 4.07400818709, 4.07036979413)]\n",
    "\n",
    "results = map(lambda x: (x[0], x[1], x[2], abs(x[2] - x[1])) , results)\n",
    "\n",
    "df = pd.DataFrame.from_records(results)\n",
    "df.columns = [\"Rank\", \"Pre-Merge RMSE\", \"Post-Merge RMSE (50k)\", \"RMSE Delta (50k)\"]\n",
    "pt = itable.PrettyTable(df, tstyle=itable.TableStyle(theme=\"theme1\"), center=True)\n",
    "pt.set_cell_style(font_weight=\"bold\", rows=[-2])\n",
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a huge result at all, but the RMSE is generally lower post-merge, which shows that this technique might have promise. The difference is pretty small, so more work would be needed to confirm that viability of this method. The results above were created from only 50,000 books (out of a total of 271,380).\n",
    "\n",
    "Lets look at the results after using both merge lists (from first 50,000 and the next 50,000). I redefine the merge_ratings() function above to use both merge_dict and merge_dict2, using an appropriate offset for merge dict2 (since its for lines 50,001 - 100,000, idx0 there represents idx50001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"/spark/merge_dict_v1_p100m100n50b10c5_xlarge2\", \"rb\")\n",
    "merge_dict2 = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# Use spark accumulators to see how many times we merge\n",
    "count = sc.accumulator(0)\n",
    "missed_count = sc.accumulator(0)\n",
    "\n",
    "def merge_ratings(tokens):\n",
    "    global count\n",
    "    global missed_count\n",
    "    # (user_id, isbn_idx, rating)\n",
    "    orig_isbn_idx = tokens[1]\n",
    "#     orig_isbn_idx = tokens[1] - 50001\n",
    "    \n",
    "    if orig_isbn_idx - 50001 in merge_dict2:\n",
    "        count += 1\n",
    "        return (tokens[0], merge_dict2[orig_isbn_idx - 50001], tokens[2])\n",
    "    elif orig_isbn_idx in merge_dict1:\n",
    "        count += 1\n",
    "        return (tokens[0], merge_dict1[orig_isbn_idx], tokens[2])\n",
    "    else:\n",
    "        missed_count += 1\n",
    "        return tokens\n",
    "\n",
    "# Read in raw rating data and convert it to proper format\n",
    "new_ratings_data = ratings_raw_data \\\n",
    "                    .filter(lambda line: line != ratings_raw_data_header) \\\n",
    "                    .map(lambda line: line.split(\";\")) \\\n",
    "                    .map(lambda tokens: convert_row(tokens)) \\\n",
    "                    .filter(lambda tokens: tokens[0] is not None) \\\n",
    "                    .map(merge_ratings).cache()\n",
    "\n",
    "# print \"Loaded %d ratings\" % new_ratings_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the same methodology above gives me:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><table style=\"color: black;border: 1px solid black;\"><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;font-weight: bold;background-color: lightgray;\">Rank</td><td style=\"color: black;font-weight: bold;background-color: lightgray;\">Pre-Merge RMSE</td><td style=\"color: black;font-weight: bold;background-color: lightgray;\">Post-Merge RMSE (50k)</td><td style=\"color: black;font-weight: bold;background-color: lightgray;\">RMSE Delta (50k)</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">20.0</td><td style=\"color: black;border: 1px solid black;\">4.26313112355</td><td style=\"color: black;border: 1px solid black;\">4.26208684307</td><td style=\"color: black;border: 1px solid black;\">0.00104428048</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">22.0</td><td style=\"color: black;border: 1px solid black;\">4.23259538535</td><td style=\"color: black;border: 1px solid black;\">4.2175599298</td><td style=\"color: black;border: 1px solid black;\">0.01503545555</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">24.0</td><td style=\"color: black;border: 1px solid black;\">4.21148751659</td><td style=\"color: black;border: 1px solid black;\">4.20655965168</td><td style=\"color: black;border: 1px solid black;\">0.00492786491</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">26.0</td><td style=\"color: black;border: 1px solid black;\">4.18826859766</td><td style=\"color: black;border: 1px solid black;\">4.18325077481</td><td style=\"color: black;border: 1px solid black;\">0.00501782285</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">28.0</td><td style=\"color: black;border: 1px solid black;\">4.16448657922</td><td style=\"color: black;border: 1px solid black;\">4.16371352081</td><td style=\"color: black;border: 1px solid black;\">0.00077305841</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">30.0</td><td style=\"color: black;border: 1px solid black;\">4.15846533055</td><td style=\"color: black;border: 1px solid black;\">4.14492062267</td><td style=\"color: black;border: 1px solid black;\">0.01354470788</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">32.0</td><td style=\"color: black;border: 1px solid black;\">4.1436364273</td><td style=\"color: black;border: 1px solid black;\">4.13621839668</td><td style=\"color: black;border: 1px solid black;\">0.00741803062</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">34.0</td><td style=\"color: black;border: 1px solid black;\">4.12220323035</td><td style=\"color: black;border: 1px solid black;\">4.12741234399</td><td style=\"color: black;border: 1px solid black;\">0.00520911364</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">36.0</td><td style=\"color: black;border: 1px solid black;\">4.11941536673</td><td style=\"color: black;border: 1px solid black;\">4.10674592613</td><td style=\"color: black;border: 1px solid black;\">0.0126694406</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">38.0</td><td style=\"color: black;border: 1px solid black;\">4.10410432488</td><td style=\"color: black;border: 1px solid black;\">4.10010399642</td><td style=\"color: black;border: 1px solid black;\">0.00400032846</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">40.0</td><td style=\"color: black;border: 1px solid black;\">4.09841351419</td><td style=\"color: black;border: 1px solid black;\">4.09361783599</td><td style=\"color: black;border: 1px solid black;\">0.0047956782</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">42.0</td><td style=\"color: black;border: 1px solid black;\">4.09207336934</td><td style=\"color: black;border: 1px solid black;\">4.08362561668</td><td style=\"color: black;border: 1px solid black;\">0.00844775266</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">44.0</td><td style=\"color: black;border: 1px solid black;\">4.08177248426</td><td style=\"color: black;border: 1px solid black;\">4.07829758906</td><td style=\"color: black;border: 1px solid black;\">0.0034748952</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"font-weight: bold;\">46.0</td><td style=\"font-weight: bold;\">4.07279330036</td><td style=\"font-weight: bold;\">4.05993951906</td><td style=\"font-weight: bold;\">0.0128537813</td></tr><tr style=\"color: black;border: 1px solid black;\"><td style=\"color: black;border: 1px solid black;\">48.0</td><td style=\"color: black;border: 1px solid black;\">4.07400818709</td><td style=\"color: black;border: 1px solid black;\">4.07202519358</td><td style=\"color: black;border: 1px solid black;\">0.00198299351</td></tr></table></center>"
      ],
      "text/plain": [
       "<itable.itable.PrettyTable at 0x7f15cbbb7fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [(20, 4.26313112355, 4.25828212238, 4.26208684307),\n",
    "            (22, 4.23259538535, 4.23275657208, 4.2175599298),\n",
    "            (24, 4.21148751659, 4.20943547919, 4.20655965168),\n",
    "            (26, 4.18826859766, 4.18930658745, 4.18325077481),\n",
    "            (28, 4.16448657922, 4.16958226847, 4.16371352081),\n",
    "            (30, 4.15846533055, 4.15713268602, 4.14492062267),\n",
    "            (32, 4.1436364273, 4.1416517817, 4.13621839668),\n",
    "            (34, 4.12220323035, 4.12264843619, 4.12741234399),\n",
    "            (36, 4.11941536673, 4.11715783255, 4.10674592613),\n",
    "            (38, 4.10410432488, 4.10227015671, 4.10010399642),\n",
    "            (40, 4.09841351419, 4.09726798097, 4.09361783599),\n",
    "            (42, 4.09207336934, 4.08903422579, 4.08362561668),\n",
    "            (44, 4.08177248426, 4.07665148098, 4.07829758906),\n",
    "            (46, 4.07279330036, 4.06946764295, 4.05993951906),\n",
    "            (48, 4.07400818709, 4.07036979413, 4.07202519358)]\n",
    "\n",
    "results = map(lambda x: (x[0], x[1], x[3], abs(x[3] - x[1])) , results)\n",
    "\n",
    "df = pd.DataFrame.from_records(results)\n",
    "df.columns = [\"Rank\", \"Pre-Merge RMSE\", \"Post-Merge RMSE (50k)\", \"RMSE Delta (50k)\"]\n",
    "pt = itable.PrettyTable(df, tstyle=itable.TableStyle(theme=\"theme1\"), center=True)\n",
    "pt.set_cell_style(font_weight=\"bold\", rows=[-2])\n",
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above. Some marginal gains in error rate, though the delta acheieved with more data (0.0128537813) is 4 times the one gained with just 50k titles. Promising maybe, but one has to compare how much computational cost LSH is, versus how much of a gain this would represent in the real world performance, and it this would be worth all the hassle\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "The first step would be to review the LSH implementation to make sure its as efficient as possible. I took a brief look at the LSH function in the lsh.py file in the module, and it generally makes sense to me. However, the code I wrote afterwards to process the results may not be the best way of doing things either (though the majority of the time was spent in the LSH routine).\n",
    "\n",
    "After confirming the effectiveness of the module, I would expand the example to use a cluster of machines. Scaling one machine was difficult, as I had to end up tweaking per-executer memory limits (I ran a few computations that took a few hours to only die of MemoryLimit exceptions; quite frustrating!). Its very time consuming preventing quick iterations of work. When working on this kind of scale, thinking-ahead is paramount. I did not have enough time to get into this, but would have been cool to see if the LSH technique would expand easily into more Spark machines. \n",
    "\n",
    "I would also tweak the LSH parameters by either 1) a deeper understanding of the space-cpu tradeoff in the parameter space and maybe 2) a meta-parameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
